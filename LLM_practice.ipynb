{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM configuration practice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LLM configuratino basic process\n",
    "\n",
    "1. pretraining(사전 훈련)으로 일반적인 언어 능력을 가르친다\n",
    "\n",
    "2. fine tuning(미세조정) 단계에서 특정 용도에 맞게 다듬는다   \n",
    "\n",
    "    > 여기까지가 기본적인 절차   \n",
    "\n",
    "\n",
    "3. 데이터베이스(혹은 인터넷) 검색 기능을 추가한다   \n",
    "\n",
    "    > 지식의 범위와 정확성을 더 높일 수 있다   \n",
    "    \n",
    "\n",
    "4. 내부적으로 질의를 반복하여 더 좋은 결론을 도출한다   \n",
    "\n",
    "    > 사람이 생각을 거듭하여 더 깊이 있는 결론을 이끌어내는 과정과 같다   \n",
    "\n",
    "\n",
    "#### the stage of practice   \n",
    "\n",
    "1. 훈련 데이터 준비\n",
    "\n",
    "2. 데이터 로더 정의\n",
    "\n",
    "3. 모델 정의\n",
    "\n",
    "4. 훈련\n",
    "\n",
    "5. 결과 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### computer\n",
    "\n",
    "* macbook pro m4 pro\n",
    "\n",
    "#### packages\n",
    "\n",
    "* miniconda=24.11.1\n",
    "\n",
    "* python=3.9.20\n",
    "    ```sh\n",
    "    conda create -n LLM python=3.9.20\n",
    "    ```\n",
    "\n",
    "* tiktoken=0.9.0\n",
    "    ```sh\n",
    "    pip install tiktoken\n",
    "    ```\n",
    "\n",
    "* torch=2.6.0\n",
    "    ```sh\n",
    "    pip3 install torch torchvision torchaudio\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 훈련 데이터 준비\n",
    "\n",
    "* [해리포터 영어 원서](https://www.kaggle.com/datasets/shubhammaindola/harry-potter-books?select=02+Harry+Potter+and+the+Chamber+of+Secrets.txt)\n",
    "    ```sh\n",
    "    curl -o LLM_configuration/data/file-name.txt \"download link\"\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_text(filename, path):\n",
    "    with open(path + '/' + filename,  'r', encoding='utf-8') as file:\n",
    "        book_text = file.read()\n",
    "        \n",
    "    cleaned_text = re.sub(r'\\n+', ' ', book_text) # 줄 바꿈을 공백으로\n",
    "    cleaned_text = re.sub(r's+', ' ', cleaned_text) # 연속되는 공백을 하나의 공백으로\n",
    "    \n",
    "    print('cleaned_' + filename, len(cleaned_text), 'characters') # 글자 수 출력\n",
    "    \n",
    "    with open(path + '/' + 'cleaned_' + filename, 'w', encoding='utf-8') as file:\n",
    "        file.write(cleaned_text) # 잘 정리된 훈련 데이터 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleaned_01_Harry_Potter_and_the_Sorcerers_Stone.txt 435335 characters\n",
      "cleaned_02_Harry_Potter_and_the_Chamber_of_Secrets.txt 487913 characters\n",
      "cleaned_03_Harry_Potter_and_the_Prisoner_of_Azkaban.txt 619717 characters\n",
      "cleaned_04_Harry_Potter_and_the_Goblet_of_Fire.txt 1091860 characters\n",
      "cleaned_05_Harry_Potter_and_the_Order_of_the_Phoenix.txt 1486941 characters\n",
      "cleaned_06_Harry_Potter_and_the_Half-Blood_Prince.txt 980175 characters\n",
      "cleaned_07_Harry_Potter_and_the_Deathly_Hallows.txt 1131296 characters\n"
     ]
    }
   ],
   "source": [
    "filename_list = ['01_Harry_Potter_and_the_Sorcerers_Stone.txt',\n",
    "                 '02_Harry_Potter_and_the_Chamber_of_Secrets.txt',\n",
    "                 '03_Harry_Potter_and_the_Prisoner_of_Azkaban.txt',\n",
    "                 '04_Harry_Potter_and_the_Goblet_of_Fire.txt',\n",
    "                 '05_Harry_Potter_and_the_Order_of_the_Phoenix.txt',\n",
    "                 '06_Harry_Potter_and_the_Half-Blood_Prince.txt',\n",
    "                 '07_Harry_Potter_and_the_Deathly_Hallows.txt']\n",
    "file_path = '/Users/kh22cho/LLM_configuration/data'\n",
    "\n",
    "for filename in filename_list:\n",
    "    clean_text(filename, file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 토큰화 진행\n",
    "\n",
    "UTF-8 BPE (Bype Pair Encoding)\n",
    "\n",
    "문자열 데이터를 숫자로 변환하는 과정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "\n",
    "tokenizer = tiktoken.get_encoding('gpt2') # gpt2에서 사용하는 tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 토큰화의 간단한 예시\n",
    "\n",
    "```python\n",
    "text = 'Harry Potter was a wizard.' # token으로 바꿀 예시 문장 | neural net이 이해할 수 있게 적당히 자른 것이 token\n",
    "\n",
    "tokens = tokenizer.encode(text) # text를 숫자로 바꾸는 과정 \n",
    "\n",
    "print('글자수 :', len(text), '토큰수 :', len(tokens))\n",
    "print(tokens) # 6개의 token들로 text를 변환함 | .도 문장의 끝이라는 의미의 token\n",
    "print(tokenizer.decode(tokens)) # 6개의 token들을 다시 decode하여 text로 원상 복구\n",
    "for t in tokens:\n",
    "    print(f'{t} >>> {tokenizer.decode([t])}')\n",
    "```\n",
    "```\n",
    "글자수 : 26 토큰수 : 6   \n",
    "[18308, 14179, 373, 257, 18731, 13]   \n",
    "Harry Potter was a wizard.   \n",
    "18308 >>> Harry   \n",
    "14179 >>>  Potter   \n",
    "373 >>>  was   \n",
    "257 >>>  a   \n",
    "18731 >>>  wizard   \n",
    "13 >>> .\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 한글과 한자가 섞여있는 문장에 대한 tokenizer 예제\n",
    "\n",
    "```python\n",
    "from transformers import AutoTokenizer # pip install transformers\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"LGAI-EXAONE/EXAONE-3.5-7.8B-Instruct\")  # KoGPT2 사용 | 가장 잘되었던 모델\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"skt/kogpt2-base-v2\")  # KoGPT2 사용\n",
    "\n",
    "print(\"Vocab size :\", len(tokenizer))\n",
    "\n",
    "text = \"대사께서는 도(道)를 얻은 모양이구려.\"\n",
    "\n",
    "tokens = tokenizer.encode(text)\n",
    "\n",
    "print(len(text), len(tokens))\n",
    "print(tokens)\n",
    "print(tokenizer.decode(tokens))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 글자 단위로 토큰화하는 예시 | 비효율적이므로 잘 사용하지 않음\n",
    "\n",
    "```python\n",
    "for char in text:\n",
    "    token_ids = tokenizer.encode(char) # 한 글자씩 인코딩(토큰화)\n",
    "    decoded = tokenizer.decode(token_ids) # 한 글자씩 디코딩\n",
    "    print(f\"{char} >>> {token_ids} >>> {decoded}\") # 한 글자 단위이므로 공백도 토큰이 됨\n",
    "```\n",
    "```\n",
    "H >>> [39] >>> H\n",
    "a >>> [64] >>> a\n",
    "r >>> [81] >>> r\n",
    "r >>> [81] >>> r\n",
    "y >>> [88] >>> y\n",
    "  >>> [220] >>>  \n",
    "P >>> [47] >>> P\n",
    "o >>> [78] >>> o\n",
    "t >>> [83] >>> t\n",
    "t >>> [83] >>> t\n",
    "e >>> [68] >>> e\n",
    "r >>> [81] >>> r\n",
    "  >>> [220] >>>  \n",
    "w >>> [86] >>> w\n",
    "a >>> [64] >>> a\n",
    "s >>> [82] >>> s\n",
    "  >>> [220] >>>  \n",
    "a >>> [64] >>> a\n",
    "  >>> [220] >>>  \n",
    "w >>> [86] >>> w\n",
    "i >>> [72] >>> i\n",
    "z >>> [89] >>> z\n",
    "a >>> [64] >>> a\n",
    "r >>> [81] >>> r\n",
    "d >>> [67] >>> d\n",
    ". >>> [13] >>> .\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 데이터 로더 (DataLoader)\n",
    "\n",
    "입력 데이터가 많아질수록 neural net도 무시무시하게 커지기 때문에\n",
    "\n",
    "전체 데이터를 한번에 사용하지 않고, 몇개씩 쪼개주는 기능을 하는 것이 ```Dataset```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, txt, max_length = 32, stride = 4):\n",
    "        self.input_ids = []\n",
    "        self.target_ids = []\n",
    "        \n",
    "        # token_ids = tokenizer.encode(\"<|endoftext|>\" + txt, allowed_special={\"<|endoftext|>\"})\n",
    "        token_ids = tokenizer.encode(txt) # 책 한권을 token으로 바꿈\n",
    "        \n",
    "        print('# of tokens in txt :', len(token_ids)) # token이 몇개정도 되는지\n",
    "        \n",
    "        for i in range(0, len(token_ids) - max_length, stride):\n",
    "            input_chunk = token_ids[i:i + max_length]\n",
    "            target_chunk = token_ids[i + 1: i + max_length + 1] # 앞의 몇개의 단어(input)가 오면, 그 다음으로 오는 단어(target)를 의미\n",
    "            self.input_ids.append(torch.tensor(input_chunk)) # input를 넣으면, \n",
    "            self.target_ids.append(torch.tensor(target_chunk)) # target하고 가급적 똑같은 대답을 하도록 훈련을 시킴\n",
    "            # example\n",
    "            # Text :   Harry Potter was a Wizard.\n",
    "            # input :  Harry Poter\n",
    "            # target :              was\n",
    "            \n",
    "    def __len__(self): # 훈련을 시킬 수 있는 조각이 전부 몇개인지 알려주는 함수\n",
    "        return len(self.input_ids)\n",
    "    \n",
    "    def __getitem__(self, idx): # DataLoader를 사용할때 실제로 호출하는 함수\n",
    "        return self.input_ids[idx], self.target_ids[idx] # input의 id와 target의 id를 쌍으로 반환"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Harry Potter 모든 책을 합쳐서 이용할 시\n",
    "\n",
    "```python\n",
    "txt = \"\" # 여러 책의 내용을 합칠 문자열\n",
    "for f in filename_list:\n",
    "    with open(file_path + '/' + 'cleaned_' + f, 'r', encoding='utf-8-sig') as file: # 선택 : -sig를 붙여서 BOM 제거\n",
    "        print('open', f)\n",
    "        txt += file.read() # 책을 읽어온다\n",
    "\n",
    "# gpu 사용이 어려울 때, txt의 일부만 이용하여 cpu에 부담을 줄이고 싶을때\n",
    "# txt = txt[:100000]\n",
    "```\n",
    "\n",
    "```\n",
    "open 01_Harry_Potter_and_the_Sorcerers_Stone.txt\n",
    "open 02_Harry_Potter_and_the_Chamber_of_Secrets.txt\n",
    "open 03_Harry_Potter_and_the_Prisoner_of_Azkaban.txt\n",
    "open 04_Harry_Potter_and_the_Goblet_of_Fire.txt\n",
    "open 05_Harry_Potter_and_the_Order_of_the_Phoenix.txt\n",
    "open 06_Harry_Potter_and_the_Half-Blood_Prince.txt\n",
    "open 07_Harry_Potter_and_the_Deathly_Hallows.txt\n",
    "# of tokens in txt : 1912071\n",
    "```\n",
    "\n",
    "mps는 너무 오래걸려서 책 한권만 이용하기로 결정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of tokens in txt : 138857\n"
     ]
    }
   ],
   "source": [
    "# with open('cleaned_한글문서.txt', 'r', encoding='utf-8-sig') as file: # 선택 : -sig를 붙여서 BOM 제거\n",
    "with open(file_path + '/' + 'cleaned_01_Harry_Potter_and_the_Sorcerers_Stone.txt', 'r', encoding='utf-8-sig') as file: # 선택: -sig를 붙여서 BOM 제거\n",
    "    txt = file.read()\n",
    "\n",
    "dataset = MyDataset(txt, max_length = 32, stride = 4) # dataset을 정의\n",
    "\n",
    "train_loader = DataLoader(dataset, batch_size=32, shuffle=True, drop_last=True) # dataset을 이용하여 pytorch의 DataLoader를 만든다\n",
    "\n",
    "# 주의 : 여기서는 코드를 단순화하기 위해 test, valid는 생략하고 train_loader만 만들었습니다\n",
    "#       관련된 ML 이론은 train vs test vs validation 등으로 검색하여 참고"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DataLoader가 내부적으로 어떻게 작동하는지\n",
    "```python\n",
    "dataiter = iter(train_loader) # loader를 iterator로 바꿔주고\n",
    "\n",
    "x, y = next(dataiter) # next를 이용하여 실제 x, y로 받아온다 | x, y는 각각 input, target이며 token이다\n",
    "\n",
    "print(tokenizer.decode(x[0].tolist()))\n",
    "print(tokenizer.decode(y[0].tolist())) # target이 하나 밀린 형태\n",
    "```\n",
    "```\n",
    "an fer to Slytherin at once, becau e it wa  hi  de tiny. Harry told the turban he didn’t want to\n",
    " fer to Slytherin at once, becau e it wa  hi  de tiny. Harry told the turban he didn’t want to be\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "print(x[0])\n",
    "print(y[0]) # target이 하나 밀린 형태 | token으로 보면 더 명확함\n",
    "```\n",
    "```\n",
    "tensor([  272, 11354,   284, 31615,   490,   259,   379,  1752,    11,   639,\n",
    "          559,   304,   340,  2082,   220, 23105,   220,   390,  7009,    13,\n",
    "         5850,  1297,   262,  7858,  3820,   339,  1422,   447,   247,    83,\n",
    "          765,   284])\n",
    "tensor([11354,   284, 31615,   490,   259,   379,  1752,    11,   639,   559,\n",
    "          304,   340,  2082,   220, 23105,   220,   390,  7009,    13,  5850,\n",
    "         1297,   262,  7858,  3820,   339,  1422,   447,   247,    83,   765,\n",
    "          284,   307])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 모델 정의\n",
    "\n",
    "뉴럴 네트워크 모델 정의\n",
    "\n",
    "모델은 교재([Build a Large Language Model (From Scratch)](https://github.com/rasbt/LLMs-from-scratch))에서 제공하는 예제 코드를 약간 수정한 정도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model's parameter\n",
    "\n",
    "# 50257 Tiktoken | 사전에 단어가 몇개나 있는지\n",
    "VOCAB_SIZE = tokenizer.n_vocab\n",
    "# VOCAB_SIZE = len(tokenizer) # AutoTokenizer일 경우\n",
    "\n",
    "CONTEXT_LENGTH = 128 # Shortened context length (orig : 1024)\n",
    "EMB_DIM = 768 # Embedding dimention\n",
    "NUM_HEADS = 12 # Number of attention heads\n",
    "NUM_LAYERS = 8 # Number of layers\n",
    "DROP_RATE = 0.1 # Dropout rate\n",
    "QKV_BIAS = False # Query-key-value bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class MultiHeadAttention(nn.Module): # self attention의 핵심이 되는 부분\n",
    "    def __init__(self, d_in, d_out):\n",
    "        super().__init__()\n",
    "        \n",
    "        assert d_out % NUM_HEADS == 0, \"d_out must be divisible by n_heads\"\n",
    "\n",
    "        self.d_out = d_out\n",
    "        self.head_dim = d_out // NUM_HEADS\n",
    "\n",
    "        self.W_query = nn.Linear(d_in, d_out, bias=QKV_BIAS)\n",
    "        self.W_key = nn.Linear(d_in, d_out, bias=QKV_BIAS)\n",
    "        self.W_value = nn.Linear(d_in, d_out, bias=QKV_BIAS)\n",
    "        self.out_proj = nn.Linear(d_out, d_out)\n",
    "        self.dropout = nn.Dropout(DROP_RATE)\n",
    "        self.register_buffer('mask', torch.triu(torch.ones(CONTEXT_LENGTH, CONTEXT_LENGTH), diagonal=1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, num_tokens, d_in = x.shape\n",
    "\n",
    "        keys = self.W_key(x)  # (b, num_tokens, d_out)\n",
    "        queries = self.W_query(x)\n",
    "        values = self.W_value(x)\n",
    "\n",
    "        keys = keys.view(b, num_tokens, NUM_HEADS, self.head_dim)\n",
    "        values = values.view(b, num_tokens, NUM_HEADS, self.head_dim)\n",
    "        queries = queries.view(b, num_tokens, NUM_HEADS, self.head_dim)\n",
    "\n",
    "        keys = keys.transpose(1, 2)\n",
    "        queries = queries.transpose(1, 2)\n",
    "        values = values.transpose(1, 2)\n",
    "\n",
    "        attn_scores = queries @ keys.transpose(2, 3)\n",
    "\n",
    "        mask_bool = self.mask.bool()[:num_tokens, :num_tokens]\n",
    "\n",
    "        attn_scores.masked_fill_(mask_bool, -torch.inf)\n",
    "\n",
    "        attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
    "        attn_weights = self.dropout(attn_weights)\n",
    "\n",
    "        context_vec = (attn_weights @ values).transpose(1, 2)\n",
    "\n",
    "        context_vec = context_vec.reshape(b, num_tokens, self.d_out)\n",
    "        context_vec = self.out_proj(context_vec)\n",
    "\n",
    "        return context_vec\n",
    "\n",
    "class LayerNorm(nn.Module): # neural net 가중치 값들이 너무 들쑥날쑥하지 않고 적당한 범위 내에 몰려있도록 만들어줌\n",
    "    def __init__(self, emb_dim):\n",
    "        super().__init__()\n",
    "        self.eps = 1e-5\n",
    "        self.scale = nn.Parameter(torch.ones(emb_dim))\n",
    "        self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean = x.mean(dim=-1, keepdim=True)\n",
    "        var = x.var(dim=-1, keepdim=True, unbiased=False)\n",
    "        norm_x = (x - mean) / torch.sqrt(var + self.eps)\n",
    "        return self.scale * norm_x + self.shift\n",
    "\n",
    "class GELU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return 0.5 * x * (1 + torch.tanh(\n",
    "            torch.sqrt(torch.tensor(2.0 / torch.pi)) *\n",
    "            (x + 0.044715 * torch.pow(x, 3))\n",
    "        ))\n",
    "\n",
    "class FeedForward(nn.Module): # Linear, GELU activation 다음에 다시 Linear가 있는 간단한 구조\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(EMB_DIM, 4 * EMB_DIM),\n",
    "            GELU(),\n",
    "            nn.Linear(4 * EMB_DIM, EMB_DIM),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "class TransformerBlock(nn.Module): # MultiHeadAttention, FeedForward, LayerNorm등이 사용됨\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.att = MultiHeadAttention(\n",
    "            d_in=EMB_DIM,\n",
    "            d_out=EMB_DIM)\n",
    "    \n",
    "        self.ff = FeedForward()\n",
    "        self.norm1 = LayerNorm(EMB_DIM)\n",
    "        self.norm2 = LayerNorm(EMB_DIM)\n",
    "        self.drop_shortcut = nn.Dropout(DROP_RATE)\n",
    "\n",
    "    def forward(self, x):\n",
    "        shortcut = x\n",
    "        x = self.norm1(x)\n",
    "        x = self.att(x)\n",
    "        x = self.drop_shortcut(x)\n",
    "        x = x + shortcut\n",
    "\n",
    "        shortcut = x\n",
    "        x = self.norm2(x)\n",
    "        x = self.ff(x)\n",
    "        x = self.drop_shortcut(x)\n",
    "        x = x + shortcut\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class GPTModel(nn.Module): # GPT model을 사용\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.tok_emb = nn.Embedding(VOCAB_SIZE, EMB_DIM)\n",
    "        self.pos_emb = nn.Embedding(CONTEXT_LENGTH, EMB_DIM)\n",
    "        self.drop_emb = nn.Dropout(DROP_RATE)\n",
    "\n",
    "        self.trf_blocks = nn.Sequential(\n",
    "            *[TransformerBlock() for _ in range(NUM_LAYERS)]) # TransformerBlock이 정의된 부분으로 이동하면,\n",
    "\n",
    "        self.final_norm = LayerNorm(EMB_DIM)\n",
    "        self.out_head = nn.Linear(EMB_DIM, VOCAB_SIZE, bias=False)\n",
    "\n",
    "    def forward(self, in_idx):\n",
    "        batch_size, seq_len = in_idx.shape\n",
    "        tok_embeds = self.tok_emb(in_idx)\n",
    "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
    "        x = tok_embeds + pos_embeds  # Shape [batch_size, num_tokens, emb_size]\n",
    "        x = self.drop_emb(x)\n",
    "        x = self.trf_blocks(x)\n",
    "        x = self.final_norm(x)\n",
    "        logits = self.out_head(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transformer architecture\n",
    "\n",
    "Transformer 구조 중에서 Masked Multi-Head Attention이라는 것은 훈련시키는 기본 원리와 밀접한 관련이 있음\n",
    "\n",
    "<img src=\"figure/Transformer_architecture.png\" width=\"30%\">\n",
    "\n",
    "화살표 왼쪽 그림의 행렬을 보면, 단어끼리 얼마나 관계가 깊은지에 대한 값을 저장한 행렬\n",
    "\n",
    "이번에는 화살표 오른쪽 그림의 오른쪽 윗부분을 보면, 숨겨져있는 부분이 있는데 이것이 Masked Multi-Head Attention\n",
    "\n",
    "데이터 셋을 만들때 다음 단어를 추측하는 것과 연관이 되어있음\n",
    "\n",
    "앞부분과 뒷부분을 같이 주면, 다음단어라는 정답을 주는 꼴이 되어버리므로 숨겨서 학습\n",
    "\n",
    "즉, 미래에 오는 단어를 모르게 학습을 하도록 네트워크 구조를 만든 것\n",
    "\n",
    "<img src=\"figure/Masked_Multi_Head_Attention.webp\" width=\"60%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GELU activation function\n",
    "\n",
    "<img src=\"./figure/GELU.png\" width=\"40%\" height=\"30%\"></img><br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 훈련\n",
    "\n",
    "nvidia GPU가 아닌 silicon mac의 GPU를 사용하려면 조금 다르게 셋팅이 필요\n",
    "\n",
    "apple에서는 GPU 대신 MPS(Metal Performance Shaders)라고 함\n",
    "\n",
    "MPS는 기존의 CUDA 또는 OpenCL과 같은 라이브러리와 달리 애플에서 직접 제공하는 프레임 워크, 따라서 애플 GPU 기술에 최적화되어 있음\n",
    "\n",
    "- [How to use GPU Acceleration in silicon mac (MPS setting)](https://towardsdatascience.com/installing-pytorch-on-apple-m1-chip-with-gpu-acceleration-3351dc44d67c/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU available in current env : True\n",
      "PyTorch is built with MPS activation : True\n",
      "Current device : mps\n"
     ]
    }
   ],
   "source": [
    "# PyTorch에서 MPS가 활성화되어 있는지 확인하는 방법\n",
    "import torch\n",
    "\n",
    "# 현재 환경에서 MPS를 사용할 수 있는지 여부\n",
    "print('GPU available in current env :', torch.backends.mps.is_available())\n",
    "\n",
    "# 현재 PyTorch 설치가 MPS 활성화로 빌드되었는지 여부 \n",
    "# True : 현재 설치된 PyTorch가 MPS 활성화로 빌드 되었음\n",
    "print('PyTorch is built with MPS activation :', torch.backends.mps.is_built())\n",
    "\n",
    "# MPS를 사용하기 위한 디바이스를 설정\n",
    "device = torch.device('mps')\n",
    "print(\"Current device :\", device)\n",
    "\n",
    "torch.manual_seed(0)\n",
    "model = GPTModel()\n",
    "model.to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0004, weight_decay=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens seen : 1024\n",
      "Tokens seen : 1025024\n",
      "Epoch : 1, Loss : 3.3148016626104657\n",
      "Allocated GPU Memory: 2.37 GB\n",
      "Tokens seen : 2049024\n",
      "Epoch : 2, Loss : 1.244698075735701\n",
      "Allocated GPU Memory: 2.37 GB\n",
      "Tokens seen : 3073024\n",
      "Epoch : 3, Loss : 0.5141318499822018\n",
      "Allocated GPU Memory: 2.37 GB\n",
      "Tokens seen : 4097024\n",
      "Epoch : 4, Loss : 0.3889944906109373\n",
      "Allocated GPU Memory: 2.37 GB\n",
      "Tokens seen : 5121024\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 23\u001b[0m\n\u001b[1;32m     21\u001b[0m epoch_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     22\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward() \u001b[38;5;66;03m# Calculate loss gradients\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# Update model weights using loss gradients | 대답을 더 잘하도록 가중치 업데이트\u001b[39;00m\n\u001b[1;32m     24\u001b[0m tokens_seen \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m input_batch\u001b[38;5;241m.\u001b[39mnumel()\n\u001b[1;32m     25\u001b[0m global_step \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/LLM/lib/python3.9/site-packages/torch/optim/optimizer.py:493\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    489\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    490\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    491\u001b[0m             )\n\u001b[0;32m--> 493\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    496\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/LLM/lib/python3.9/site-packages/torch/optim/optimizer.py:91\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     90\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[0;32m---> 91\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     93\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[0;32m~/miniconda3/envs/LLM/lib/python3.9/site-packages/torch/optim/adamw.py:243\u001b[0m, in \u001b[0;36mAdamW.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    230\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m cast(Tuple[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mfloat\u001b[39m], group[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    232\u001b[0m     has_complex \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[1;32m    233\u001b[0m         group,\n\u001b[1;32m    234\u001b[0m         params_with_grad,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    240\u001b[0m         state_steps,\n\u001b[1;32m    241\u001b[0m     )\n\u001b[0;32m--> 243\u001b[0m     \u001b[43madamw\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    244\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    245\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    246\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    247\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    248\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    249\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    250\u001b[0m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    251\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdifferentiable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    260\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfused\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    261\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgrad_scale\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    262\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    263\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    264\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/miniconda3/envs/LLM/lib/python3.9/site-packages/torch/optim/optimizer.py:154\u001b[0m, in \u001b[0;36m_disable_dynamo_if_unsupported.<locals>.wrapper.<locals>.maybe_fallback\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m disabled_func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 154\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/LLM/lib/python3.9/site-packages/torch/optim/adamw.py:875\u001b[0m, in \u001b[0;36madamw\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    872\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    873\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adamw\n\u001b[0;32m--> 875\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    887\u001b[0m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    889\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    890\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    891\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    892\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    893\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    894\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/LLM/lib/python3.9/site-packages/torch/optim/adamw.py:477\u001b[0m, in \u001b[0;36m_single_tensor_adamw\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable, has_complex)\u001b[0m\n\u001b[1;32m    475\u001b[0m         denom \u001b[38;5;241m=\u001b[39m (max_exp_avg_sqs[i]\u001b[38;5;241m.\u001b[39msqrt() \u001b[38;5;241m/\u001b[39m bias_correction2_sqrt)\u001b[38;5;241m.\u001b[39madd_(eps)\n\u001b[1;32m    476\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 477\u001b[0m         denom \u001b[38;5;241m=\u001b[39m (\u001b[43mexp_avg_sq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbias_correction2_sqrt\u001b[49m)\u001b[38;5;241m.\u001b[39madd_(eps)\n\u001b[1;32m    479\u001b[0m     param\u001b[38;5;241m.\u001b[39maddcdiv_(exp_avg, denom, value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39mstep_size)\n\u001b[1;32m    481\u001b[0m \u001b[38;5;66;03m# Lastly, switch back to complex view\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tokens_seen, global_step = 0, -1\n",
    "\n",
    "losses = []\n",
    "\n",
    "for epoch in range(30):\n",
    "    model.train() # Set model to training mode\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    \n",
    "    # input하고 target을 받아 neural net에 넣음 \n",
    "    # 이때 input과 target을 하나씩이 아닌 묶음, batch로 넣음\n",
    "    # 만약 gpu 메모리가 적은 경우, train_loader 초기화 과정에서 batch size를 낮추면 됨\n",
    "    for input_batch, target_batch in train_loader:\n",
    "        optimizer.zero_grad() # Reset loss gradients from previous batch iteration\n",
    "        \n",
    "        # train_loader로부터 input, target batch를 받아 device로 복사\n",
    "        input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "        \n",
    "        logits = model(input_batch)\n",
    "        loss = torch.nn.functional.cross_entropy(logits.flatten(0, 1), target_batch.flatten()) # 대답을 얼마나 잘했는지 평가\n",
    "        epoch_loss += loss.item()\n",
    "        loss.backward() # Calculate loss gradients\n",
    "        optimizer.step() # Update model weights using loss gradients | 대답을 더 잘하도록 가중치 업데이트\n",
    "        tokens_seen += input_batch.numel()\n",
    "        global_step += 1\n",
    "        \n",
    "        if global_step %1000 == 0:\n",
    "            print(f'Tokens seen : {tokens_seen}')\n",
    "        # Optional evaluation step\n",
    "    \n",
    "    avg_loss = epoch_loss / len(train_loader)\n",
    "    losses.append(avg_loss)\n",
    "    print(f'Epoch : {epoch + 1}, Loss : {avg_loss}')\n",
    "    # 에포크가 끝난 후 메모리 사용량 출력\n",
    "    print(f\"Allocated GPU Memory: {torch.mps.current_allocated_memory() / (1024 ** 3):.2f} GB\")\n",
    "    torch.save(model.state_dict(), 'model_' + str(epoch + 1).zfill(3) + '.pth') \n",
    "    \n",
    "# 주의 : 여기서는 편의상 모든 데이터를 train에 사용\n",
    "#       ML에서는 일부 데이터를 validation에 사용하는 것이 일반적       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAHFCAYAAAAOmtghAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8ekN5oAAAACXBIWXMAAA9hAAAPYQGoP6dpAABQ70lEQVR4nO3deVxVdeL/8de9LJdFQFBZVNxSwT3TTMwls1wzzZppT6dmGksrM78l2p5JNTXtaf6mdBprasolZzTTUlxSS3NDRVwRVBA3Ftnhnt8fJkXgFRA4cO/7+Xich3MPn3Pv+x7PyLuzWgzDMBARERFxElazA4iIiIhUJ5UbERERcSoqNyIiIuJUVG5ERETEqajciIiIiFNRuRERERGnonIjIiIiTkXlRkRERJyKyo2IiIg4FZUbEQcsFkuFptjY2Mv6nOeffx6LxVKlZWNjY6slw+V89ldffVXrn10VmzZt4g9/+ANhYWF4enoSGhrKbbfdxsaNG82OVkZiYqLDbe755583OyKtWrXipptuMjuGSBnuZgcQqct+/0vvpZdeYvXq1axatarU/I4dO17W5/z5z39m6NChVVr2qquuYuPGjZedwdm9++67TJo0iV69evHaa6/RsmVLkpKSeP/99+nbty9vv/02EydONDtmGY888gh33XVXmfnNmzc3IY1I/aByI+JA7969S71u0qQJVqu1zPzfy8nJwcfHp8Kf07x58yr/svL3979kHlf3ww8/MGnSJIYPH86iRYtwd//1n7477riDW265hccee4zu3btz7bXX1lqu3NxcvLy8HO61a9Gihf5+RSpJh6VELtN1111H586dWbt2LX369MHHx4f7778fgC+++ILBgwcTFhaGt7c3HTp0YOrUqWRnZ5d6j/IOS13Y5b98+XKuuuoqvL29iYyM5OOPPy41rrzDUuPGjaNBgwYcOHCA4cOH06BBA8LDw3niiSfIz88vtfzRo0e57bbb8PPzo2HDhtx9991s3rwZi8XCvHnzqmUd7dq1i1GjRhEYGIiXlxdXXnkl//znP0uNsdvtzJgxg4iICLy9vWnYsCFdu3bl7bffLhlz8uRJHnzwQcLDw7HZbDRp0oRrr72W7777zuHnx8TEYLFYmDVrVqliA+Du7s4HH3yAxWLhlVdeAWDx4sVYLBa+//77Mu81a9YsLBYLO3fuLJm3ZcsWbr75ZoKCgvDy8qJ79+785z//KbXcvHnzsFgsrFixgvvvv58mTZrg4+NT5u+jKi5sg+vWraN37954e3vTrFkznnnmGYqLi0uNPXPmDA8//DDNmjXD09OTNm3aMH369DI57HY77777LldeeWXJ30fv3r1ZsmRJmc+/1Daak5PDlClTaN26NV5eXgQFBdGzZ0/+/e9/X/Z3FymP9tyIVIOUlBTuuecennzySWbOnInVev6/G/bv38/w4cOZNGkSvr6+7N27l1dffZWffvqpzKGt8uzYsYMnnniCqVOnEhISwj/+8Q8eeOAB2rZtS//+/R0uW1hYyM0338wDDzzAE088wdq1a3nppZcICAjg2WefBSA7O5uBAwdy5swZXn31Vdq2bcvy5cu5/fbbL3+l/CIhIYE+ffoQHBzMO++8Q6NGjZg/fz7jxo3jxIkTPPnkkwC89tprPP/88zz99NP079+fwsJC9u7dS3p6esl73XvvvWzdupWXX36Z9u3bk56eztatWzl9+vRFP7+4uJjVq1fTs2fPi+4dCw8Pp0ePHqxatYri4mJuuukmgoODmTt3LoMGDSo1dt68eVx11VV07doVgNWrVzN06FCuueYaZs+eTUBAAJ9//jm33347OTk5jBs3rtTy999/PyNGjOBf//oX2dnZeHh4OFx/drudoqKiMvN/X9JSU1O54447mDp1Ki+++CJLly5lxowZnD17lvfeew+AvLw8Bg4cyMGDB3nhhRfo2rUr69atIyYmhu3bt7N06dKS9xs3bhzz58/ngQce4MUXX8TT05OtW7eSmJhY6nMrso1OnjyZf/3rX8yYMYPu3buTnZ3Nrl27HP69iVwWQ0QqbOzYsYavr2+peQMGDDAA4/vvv3e4rN1uNwoLC401a9YYgLFjx46Snz333HPG7//v2LJlS8PLy8s4cuRIybzc3FwjKCjI+Otf/1oyb/Xq1QZgrF69ulROwPjPf/5T6j2HDx9uRERElLx+//33DcD45ptvSo3761//agDG3LlzHX6nC5/95ZdfXnTMHXfcYdhsNiMpKanU/GHDhhk+Pj5Genq6YRiGcdNNNxlXXnmlw89r0KCBMWnSJIdjfi81NdUAjDvuuMPhuNtvv90AjBMnThiGYRiTJ082vL29S/IZhmHs2bPHAIx33323ZF5kZKTRvXt3o7CwsNT73XTTTUZYWJhRXFxsGIZhzJ071wCM++67r0K5Dx8+bAAXndatW1cy9sI2+PXXX5d6j7/85S+G1Wot2YZmz55d7nbx6quvGoCxYsUKwzAMY+3atQZgTJ8+3WHGim6jnTt3NkaPHl2h7y1SHXRYSqQaBAYGcv3115eZf+jQIe666y5CQ0Nxc3PDw8ODAQMGABAfH3/J973yyitp0aJFyWsvLy/at2/PkSNHLrmsxWJh5MiRpeZ17dq11LJr1qzBz8+vzMnMd9555yXfv6JWrVrFoEGDCA8PLzV/3Lhx5OTklJy03atXL3bs2MHDDz/Mt99+S2ZmZpn36tWrF/PmzWPGjBls2rSJwsLCastpGAZAyeHB+++/n9zcXL744ouSMXPnzsVms5Wc4HvgwAH27t3L3XffDUBRUVHJNHz4cFJSUkhISCj1Obfeemulcj322GNs3ry5zHTllVeWGufn58fNN99cat5dd92F3W5n7dq1wPm/C19fX2677bZS4y7sXbpwGO6bb74BYMKECZfMV5FttFevXnzzzTdMnTqV2NhYcnNzK/blRapI5UakGoSFhZWZd+7cOfr168ePP/7IjBkziI2NZfPmzSxcuBCgQv/AN2rUqMw8m81WoWV9fHzw8vIqs2xeXl7J69OnTxMSElJm2fLmVdXp06fLXT9NmzYt+TlAdHQ0r7/+Ops2bWLYsGE0atSIQYMGsWXLlpJlvvjiC8aOHcs//vEPoqKiCAoK4r777iM1NfWin9+4cWN8fHw4fPiww5yJiYn4+PgQFBQEQKdOnbj66quZO3cucP7w1vz58xk1alTJmBMnTgAwZcoUPDw8Sk0PP/wwAKdOnSr1OeWtC0eaN29Oz549y0wNGjQoNa68v7PQ0FDg13V8+vRpQkNDy5zfFRwcjLu7e8m4kydP4ubmVrK8IxXZRt955x2eeuopFi9ezMCBAwkKCmL06NHs37//ku8vUhUqNyLVoLyrXVatWsXx48f5+OOP+fOf/0z//v3p2bMnfn5+JiQsX6NGjUp+Qf+Wo7JQlc9ISUkpM//48ePA+fIB588hmTx5Mlu3buXMmTP8+9//Jjk5mSFDhpCTk1My9q233iIxMZEjR44QExPDwoULy5zX8ltubm4MHDiQLVu2cPTo0XLHHD16lJ9//pnrr78eNze3kvl/+tOf2LRpE/Hx8SxfvpyUlBT+9Kc/lfz8Qvbo6Ohy966Ut4elqvczuhRHf48XCsiFv+8Le6kuSEtLo6ioqOT7NGnShOLi4mrbDnx9fXnhhRfYu3cvqampzJo1i02bNpXZsyhSXVRuRGrIhV9iNput1PwPP/zQjDjlGjBgAFlZWSWHIS74/PPPq+0zBg0aVFL0fuuTTz7Bx8en3MucGzZsyG233caECRM4c+ZMmZNY4fwl0hMnTuTGG29k69atDjNER0djGAYPP/xwmauHiouLeeihhzAMg+jo6FI/u/POO/Hy8mLevHnMmzePZs2aMXjw4JKfR0RE0K5dO3bs2FHu3pXaLLNZWVllrmT67LPPsFqtJSf2Dho0iHPnzrF48eJS4z755JOSnwMMGzYMOH9lWHULCQlh3Lhx3HnnnSQkJJQUV5HqpKulRGpInz59CAwMZPz48Tz33HN4eHjw6aefsmPHDrOjlRg7dixvvvkm99xzDzNmzKBt27Z88803fPvttwAlV31dyqZNm8qdP2DAAJ577jn+97//MXDgQJ599lmCgoL49NNPWbp0Ka+99hoBAQEAjBw5ks6dO9OzZ0+aNGnCkSNHeOutt2jZsiXt2rUjIyODgQMHctdddxEZGYmfnx+bN29m+fLljBkzxmG+a6+9lrfeeotJkybRt29fJk6cSIsWLUpu4vfjjz/y1ltv0adPn1LLNWzYkFtuuYV58+aRnp7OlClTyqyTDz/8kGHDhjFkyBDGjRtHs2bNOHPmDPHx8WzdupUvv/yyQuvwYpKSkspdv02aNOGKK64oed2oUSMeeughkpKSaN++PcuWLeP//b//x0MPPVRyTsx9993H+++/z9ixY0lMTKRLly6sX7+emTNnMnz4cG644QYA+vXrx7333suMGTM4ceIEN910EzabjW3btuHj48MjjzxSqe9wzTXXcNNNN9G1a1cCAwOJj4/nX//6F1FRUZW6H5RIhZl7PrNI/XKxq6U6depU7vgNGzYYUVFRho+Pj9GkSRPjz3/+s7F169YyVyJd7GqpESNGlHnPAQMGGAMGDCh5fbGrpX6f82Kfk5SUZIwZM8Zo0KCB4efnZ9x6663GsmXLyr365vcufPbFpguZ4uLijJEjRxoBAQGGp6en0a1btzJXYr3xxhtGnz59jMaNGxuenp5GixYtjAceeMBITEw0DMMw8vLyjPHjxxtdu3Y1/P39DW9vbyMiIsJ47rnnjOzsbIc5L9i4caNx2223GSEhIYa7u7sRHBxsjBkzxtiwYcNFl1mxYkXJ99m3b1+5Y3bs2GH88Y9/NIKDgw0PDw8jNDTUuP76643Zs2eXjLlwtdTmzZsrlPVSV0vdfffdJWMvbIOxsbFGz549DZvNZoSFhRnTpk0rcxXX6dOnjfHjxxthYWGGu7u70bJlSyM6OtrIy8srNa64uNh48803jc6dOxuenp5GQECAERUVZfz3v/8tGVPRbXTq1KlGz549jcDAQMNmsxlt2rQxHn/8cePUqVMVWhcilWUxjN8dfBURlzdz5kyefvppkpKSdJv/euC6667j1KlT7Nq1y+woInWCDkuJuLgLN3iLjIyksLCQVatW8c4773DPPfeo2IhIvaRyI+LifHx8ePPNN0lMTCQ/P58WLVrw1FNP8fTTT5sdTUSkSnRYSkRERJyKLgUXERERp6JyIyIiIk5F5UZEREScisudUGy32zl+/Dh+fn41dht0ERERqV6GYZCVlUXTpk0veYNRlys3x48fL/N0YhEREakfkpOTL3mbCpcrNxee85KcnIy/v7/JaURERKQiMjMzCQ8Pr9Dz2lyu3Fw4FOXv769yIyIiUs9U5JQSnVAsIiIiTkXlRkRERJyKyo2IiIg4FZUbERERcSoqNyIiIuJUVG5ERETEqajciIiIiFNRuRERERGnonIjIiIiTkXlRkRERJyKyo2IiIg4FZUbERERcSoqN9UoLSuPnUfTzY4hIiLi0lRuqsnPR84y6I01PDR/KzkFRWbHERERcVkqN9UkMtQPfy8PjqXn8ubKfWbHERERcVkqN9XE1+bOjNGdAfho/WF2HcswOZGIiIhrUrmpRgMjg7mpaxh2A6Yu3ElRsd3sSCIiIi5H5aaaPTuyI/5e7uw6lsm8DYlmxxEREXE5KjfVLNjPi2nDOwDwxop9JJ/JMTmRiIiIa1G5qQF/7BlOr9ZB5BYW88zXuzAMw+xIIiIiLkPlpgZYrRZm3tIFTzcrsQkn+d/OFLMjiYiIuAyVmxrSNrgBDw+8AoAX/rubjJxCkxOJiIi4BpWbGvTQdVdwRRNfTp0rIOabeLPjiIiIuASVmxpkc3cjZkxXAD7fnMyPh06bnEhERMT5qdzUsF6tg7izVwsAohfFkV9UbHIiERER56ZyUwumDoukiZ+NQyez+WD1QbPjiIiIODWVm1oQ4O3B8yM7AfBB7AEOpGWZnEhERMR5qdzUkuFdQhkUGUxhsUH0wjjsdt37RkREpCao3NQSi8XCi6M74+PpxubEs3y+OdnsSCIiIk5J5aYWNWvozRODIwCI+SaetMw8kxOJiIg4H5WbWjauTyu6Ng8gK6+IF/63x+w4IiIiTkflppa5/fJoBjerhaU7U/g+/oTZkURERJyKyo0JOjcL4M99WwPwzOJdZOcXmZxIRETEeajcmOSxG9oRHuTN8Yw83lixz+w4IiIiTkPlxiQ+nu7MGN0FgHkbDrMjOd3cQCIiIk5C5cZEA9o3YdSVTbEbMHVhHIXFdrMjiYiI1HsqNyZ75qaOBHh7EJ+SycfrD5sdR0REpN5TuTFZ4wY2po/oAMCb3+0j+UyOyYlERETqN5WbOuAPPZrTu00QeYV2pi/ehWHo0QwiIiJVpXJTB1gs5+994+luZe2+kyzZcdzsSCIiIvWWyk0d0aZJAx69vi0AL/53D2ezC0xOJCIiUj+p3NQhD/a/gvYhDTidXcDMZfFmxxEREamXVG7qEE93KzFjzt/75sufj7Lh4CmTE4mIiNQ/Kjd1TI+WQdzTuwUA0xftIq+w2OREIiIi9YvKTR305NBIgv1sHD6VzfurD5gdR0REpF5RuamD/L08eHFUJwBmxR4kITXL5EQiIiL1h6nlZtasWXTt2hV/f3/8/f2Jiorim2++cbjMmjVr6NGjB15eXrRp04bZs2fXUtraNaRTKDd2DKHIbhC9cCd2u+59IyIiUhGmlpvmzZvzyiuvsGXLFrZs2cL111/PqFGj2L17d7njDx8+zPDhw+nXrx/btm1j2rRpPProoyxYsKCWk9c8i8XCi6M64evpxtakdD79KcnsSCIiIvWCxahjt8MNCgrib3/7Gw888ECZnz311FMsWbKE+PhfL5MeP348O3bsYOPGjRV6/8zMTAICAsjIyMDf37/acteUeT8c5vn/7sHP5s7KyQMIDfAyO5KIiEitq8zv7zpzzk1xcTGff/452dnZREVFlTtm48aNDB48uNS8IUOGsGXLFgoLC8tdJj8/n8zMzFJTfXJvVCu6hTckK7+I55eUv0dLREREfmV6uYmLi6NBgwbYbDbGjx/PokWL6NixY7ljU1NTCQkJKTUvJCSEoqIiTp0q/54wMTExBAQElEzh4eHV/h1qkpvVwitjuuButbB8dyordqeaHUlERKROM73cREREsH37djZt2sRDDz3E2LFj2bNnz0XHWyyWUq8vHFX7/fwLoqOjycjIKJmSk5OrL3wt6RDmz1/6twHg2a93k5VX/l4qERERqQPlxtPTk7Zt29KzZ09iYmLo1q0bb7/9drljQ0NDSU0tveciLS0Nd3d3GjVqVO4yNput5GqsC1N99NigdrRs5ENqZh5vrNhndhwREZE6y/Ry83uGYZCfn1/uz6Kioli5cmWpeStWrKBnz554eHjURjzTeHm48fLo849m+OfGRLYlnTU5kYiISN1karmZNm0a69atIzExkbi4OKZPn05sbCx33303cP6Q0n333Vcyfvz48Rw5coTJkycTHx/Pxx9/zEcffcSUKVPM+gq1qm+7xoy5qhmGAdEL4ygstpsdSUREpM4xtdycOHGCe++9l4iICAYNGsSPP/7I8uXLufHGGwFISUkhKenX+7u0bt2aZcuWERsby5VXXslLL73EO++8w6233mrWV6h1T4/oSKCPB3tTs/h/6w6ZHUdERKTOqXP3ualp9e0+N+VZ8PNRnvhyBzZ3Kyse70/LRr5mRxIREalR9fI+N1JxY65qxrVtG5FfZGf6ol24WD8VERFxSOWmHrJYLLw8ugs2dyvrD5xi0bZjZkcSERGpM1Ru6qlWjX157IZ2ALz0vz2cyS4wOZGIiEjdoHJTj/2lXxsiQ/04m1PIjKUXv/GhiIiIK1G5qcc83KzEjOmCxQILtx5j/f7yH0EhIiLiSlRu6rnuLQK5r3dLAKYvjiOvsNjkRCIiIuZSuXECU4ZEEOrvxZHTObzz/X6z44iIiJhK5cYJ+Hl58OKoTgDMWXuI+JRMkxOJiIiYR+XGSQzuFMrQTqEU2Q2iF8ZRbNe9b0RExDWp3DiR52/uhJ/Nne3J6czfdMTsOCIiIqZQuXEioQFePDksEoDXlu/leHquyYlERERqn8qNk7m7VwuuatGQ7IJinv16tx7NICIiLkflxslYrRZixnTF3Wrhu/gTfLs71exIIiIitUrlxglFhPoxfsAVADy3ZDeZeYUmJxIREak9KjdOauL1bWnd2JcTmfn8bXmC2XFERERqjcqNk/LycOPlWzoDMP/HI/x85IzJiURERGqHyo0T63NFY/7QozmGAdEL4ygospsdSUREpMap3Di5acM70MjXk30nzjFn7UGz44iIiNQ4lRsnF+jryTM3dQTgnVUHOHTynMmJREREapbKjQsYdWVT+rVrTEGRnemLduneNyIi4tRUblyAxWLh5dFd8PKwsvHQab76+ajZkURERGqMyo2LaNHIh8dvaA/Ay8viOXUu3+REIiIiNUPlxoU80Lc1HcP8Sc8pZMb/9pgdR0REpEao3LgQdzcrMWO6YLXA4u3HWbPvpNmRREREqp3KjYvpFt6QcX1aAzB9URw5BUUmJxIREaleKjcu6InB7Wka4MXRs7m8/d1+s+OIiIhUK5UbF+Rrc+fFUecfzfCP9YfZfTzD5EQiIiLVR+XGRd3QMYQRXcIothtEL4yj2K5734iIiHNQuXFhz43siJ+XOzuPZvDPDYlmxxEREakWKjcuLNjfi+hhHQB4fUUCx9JzTU4kIiJy+VRuXNwdV4dzdatAcgqKeWaxHs0gIiL1n8qNi7NaLcSM6YKHm4VVe9NYFpdqdiQREZHLonIjtA3246Hr2gLw/H93k5FbaHIiERGRqlO5EQAevu4K2jTx5WRWPq8u32t2HBERkSpTuREAvDzcmHlLFwA++zGJzYlnTE4kIiJSNSo3UqJ3m0bccXU4ANEL48gvKjY5kYiISOWp3Egp0cM60LiBjQNp55gde8jsOCIiIpWmciOlBPh48NzIjgC8v/oAB9LOmZxIRESkclRupIybuoZxXUQTCortTFsYh12PZhARkXpE5UbKsFgsvDSqM94ebvyUeIb/bEk2O5KIiEiFqdxIucKDfHhicHsAZi6L52RWvsmJREREKkblRi5qXJ9WdG7mT2ZeES/+b4/ZcURERCpE5UYuyt3NyitjumK1wH93HGf13jSzI4mIiFySyo041LlZAA/0bQ3A04t3kZ1fZHIiERERx1Ru5JIev7E9zRp6cyw9lzdX7jM7joiIiEMqN3JJPp7uzLilMwAf/3CYuKMZJicSERG5OFPLTUxMDFdffTV+fn4EBwczevRoEhISHC4TGxuLxWIpM+3dq4c91qSBEcGM7NYUuwHRi3ZSVGw3O5KIiEi5TC03a9asYcKECWzatImVK1dSVFTE4MGDyc7OvuSyCQkJpKSklEzt2rWrhcSu7dmbOuLv5c6uY5nM25BodhwREZFyuZv54cuXLy/1eu7cuQQHB/Pzzz/Tv39/h8sGBwfTsGHDGkwnv9fEz8b0ER14akEcb6zYx5BOoYQH+ZgdS0REpJQ6dc5NRsb5czmCgoIuObZ79+6EhYUxaNAgVq9efdFx+fn5ZGZmlpqk6v7YM5xrWgeRW1jM04t3YRh6NIOIiNQtdabcGIbB5MmT6du3L507d77ouLCwMObMmcOCBQtYuHAhERERDBo0iLVr15Y7PiYmhoCAgJIpPDy8pr6CS7BYLMwc0wVPNytr9p3kvztTzI4kIiJSisWoI//pPWHCBJYuXcr69etp3rx5pZYdOXIkFouFJUuWlPlZfn4++fm/PjogMzOT8PBwMjIy8Pf3v+zcruqd7/fz95X7aNzAk+8mD6Chj6fZkURExIllZmYSEBBQod/fdWLPzSOPPMKSJUtYvXp1pYsNQO/evdm/f3+5P7PZbPj7+5ea5PKNH3AFbYMbcOpcATHLdKWaiIjUHaaWG8MwmDhxIgsXLmTVqlW0bt26Su+zbds2wsLCqjmdOOLpbiVmTBcAvtiSzKZDp01OJCIicp6p5WbChAnMnz+fzz77DD8/P1JTU0lNTSU3N7dkTHR0NPfdd1/J67feeovFixezf/9+du/eTXR0NAsWLGDixIlmfAWXdnWrIO66pgUA0xbFkVdYbHIiERERk8vNrFmzyMjI4LrrriMsLKxk+uKLL0rGpKSkkJSUVPK6oKCAKVOm0LVrV/r168f69etZunQpY8aMMeMruLynhkbSxM/GoZPZfBB70Ow4IiIideeE4tpSmROSpGKWxaXw8Kdb8XCzsOzRfrQL8TM7koiIOJl6d0Kx1G/DOodyQ4dgCosNohfGYbe7VF8WEZE6RuVGLpvFYuHFUZ3x9XRjy5Gz/Htz0qUXEhERqSEqN1Itmjb05onBEQC88s1e0jLzTE4kIiKuSuVGqs3YPq3o2jyArLwiXvjvHrPjiIiIi1K5kWrjZrUQM6YLblYLS+NS+G7PCbMjiYiIC1K5kWrVqWkAf+53/maMz369i3P5RSYnEhERV6NyI9Vu0qD2hAd5czwjjzdWJJgdR0REXIzKjVQ7b083Xh59/tEM8zYksj053dxAIiLiUlRupEb0b9+E0Vc2xTAgemEchcV2syOJiIiLULmRGvP0TR1p6ONBfEomH60/bHYcERFxESo3UmMaN7AxfXgHAN76bh9Jp3NMTiQiIq5A5UZq1G09mhPVphF5hXamL47DxR5lJiIiJlC5kRplsViYOaYLnu5W1u0/xdfbj5sdSUREnJzKjdS41o19eWxQOwBe/N8ezmYXmJxIREScmcqN1Iq/9GtDRIgfZ7ILeHlZvNlxRETEiancSK3wdLcyc0wXLBb46uejbDhwyuxIIiLipFRupNb0aBnIPde0BGDaojjyCotNTiQiIs5I5UZq1f8NjSDE30bi6RzeW3XA7DgiIuKEVG6kVvl7efDCzZ0BmL3mIAmpWSYnEhERZ6NyI7VuaOdQBncMochuMHXhTux23ftGRESqj8qNmOKFUZ1oYHNnW1I6n/54xOw4IiLiRFRuxBRhAd48OTQCgFeXJ5CakWdyIhERcRYqN2Kau69pyZXhDTmXX8RzS3aZHUdERJyEyo2Yxs1qIWZMF9ytFr7dfYJvd6eaHUlERJyAyo2YqkOYPw/2bwPAc1/vJiuv0OREIiJS36nciOkeHdSOlo18SM3M4/VvE8yOIyIi9ZzKjZjOy8ONmbd0AeCTTUfYmnTW5EQiIlKfqdxInXBt28bcelVzDAOiF8RRWGw3O5KIiNRTKjdSZ0wf0YEgX08STmQxZ+0hs+OIiEg9pXIjdUaQrydPj+gAwNvf7yfxVLbJiUREpD5SuZE65ZbuzejbtjEFRXamL47DMPRoBhERqRyVG6lTLBYLL9/SGZu7lR8OnGbh1mNmRxIRkXpG5UbqnJaNfJl0Q3sAZizdw+lz+SYnEhGR+kTlRuqkP/drTWSoH2dzCnl5abzZcUREpB5RuZE6ycPNyiu3dsVigYXbjrFu/0mzI4mISD2hciN11pXhDRkb1QqA6Yt2kVtQbG4gERGpF1RupE6bMiSCsAAvks7k8M6q/WbHERGRekDlRuq0BjZ3XhzVGYA5aw8Rn5JpciIREanrVG6kzruxYwjDOodSbDeYujCOYrvufSMiIhenciP1wvM3d8LP5s6O5HT+tTHR7DgiIlKHqdxIvRDi78VTwyIB+Nu3CRxPzzU5kYiI1FUqN1Jv3NWrBT1aBpJdUMyzX+/SoxlERKRcKjdSb1itFmLGdMHDzcJ38Wks35VqdiQREamDVG6kXmkf4sf4AVcA8NyS3WTmFZqcSERE6hqVG6l3JgxsS+vGvqRl5fPa8r1mxxERkTpG5UbqHS8PN2be0gWA+ZuS2JJ4xuREIiJSl6jcSL0UdUUj/tizOQDRC+MoKLKbnEhEROoKU8tNTEwMV199NX5+fgQHBzN69GgSEhIuudyaNWvo0aMHXl5etGnThtmzZ9dCWqlrpg3vQCNfT/annePDNQfNjiMiInWEqeVmzZo1TJgwgU2bNrFy5UqKiooYPHgw2dnZF13m8OHDDB8+nH79+rFt2zamTZvGo48+yoIFC2oxudQFDX08eXZkRwDeXXWAgyfPmZxIRETqAotRh24WcvLkSYKDg1mzZg39+/cvd8xTTz3FkiVLiI+PL5k3fvx4duzYwcaNGy/5GZmZmQQEBJCRkYG/v3+1ZRdzGIbB2LmbWbvvJL3bBPHvv/TGYrGYHUtERKpZZX5/16lzbjIyMgAICgq66JiNGzcyePDgUvOGDBnCli1bKCwse1lwfn4+mZmZpSZxHhaLhZdHd8bLw8qmQ2f48uejZkcSERGT1ZlyYxgGkydPpm/fvnTu3Pmi41JTUwkJCSk1LyQkhKKiIk6dOlVmfExMDAEBASVTeHh4tWcXc4UH+TD5xvYAvLw0nlPn8k1OJCIiZqoz5WbixIns3LmTf//735cc+/vDDheOrJV3OCI6OpqMjIySKTk5uXoCS51y/7Wt6RjmT0ZuIS/9b4/ZcURExER1otw88sgjLFmyhNWrV9O8eXOHY0NDQ0lNLX3b/bS0NNzd3WnUqFGZ8TabDX9//1KTOB93Nyuv3NoFqwW+3n6c2IQ0syOJiIhJTC03hmEwceJEFi5cyKpVq2jduvUll4mKimLlypWl5q1YsYKePXvi4eFRU1GlHujavCF/uvb8NvT04l3kFBSZnEhERMxgarmZMGEC8+fP57PPPsPPz4/U1FRSU1PJzc0tGRMdHc19991X8nr8+PEcOXKEyZMnEx8fz8cff8xHH33ElClTzPgKUsdMvrE9zRp6c/RsLm99t9/sOCIiYoIqlZvk5GSOHv31qpSffvqJSZMmMWfOnEq9z6xZs8jIyOC6664jLCysZPriiy9KxqSkpJCUlFTyunXr1ixbtozY2FiuvPJKXnrpJd555x1uvfXWqnwVcTK+NndeGt0JgI/WH2bXsQyTE4mISG2r0n1u+vXrx4MPPsi9995LamoqERERdOrUiX379vHoo4/y7LPP1kTWaqH73LiGCZ9tZenOFLo0C2DxhGtxs+reNyIi9VmN3+dm165d9OrVC4D//Oc/dO7cmQ0bNvDZZ58xb968qrylSLV6bmRH/LzciTuWwbwNiWbHERGRWlSlclNYWIjNZgPgu+++4+abbwYgMjKSlJSU6ksnUkXBfl5MG94BgDdWJHD0bI7JiUREpLZUqdx06tSJ2bNns27dOlauXMnQoUMBOH78eLmXY4uY4fae4fRqFUROQTHPfr2bOvSkERERqUFVKjevvvoqH374Iddddx133nkn3bp1A2DJkiUlh6tEzGa1Wpg5pjOeblZW7U1jaZz2KoqIuIIqPzizuLiYzMxMAgMDS+YlJibi4+NDcHBwtQWsbjqh2PW8uXIfb3+/n8YNbHw/eQABProfkohIfVPjJxTn5uaSn59fUmyOHDnCW2+9RUJCQp0uNuKaHh54BW2a+HLqXD6vLN9rdhwREalhVSo3o0aN4pNPPgEgPT2da665hjfeeIPRo0cza9asag0ocrls7m7E3NIFgH//lMRPh8+YnEhERGpSlcrN1q1b6devHwBfffUVISEhHDlyhE8++YR33nmnWgOKVIdr2jTizl7nnwgfvXAn+UXFJicSEZGaUqVyk5OTg5+fH3D+uU5jxozBarXSu3dvjhw5Uq0BRarL1KEdaNzAxsGT2cyKPWh2HBERqSFVKjdt27Zl8eLFJCcn8+233zJ48GDg/NO5dZKu1FUBPh48f3NHAD5YfZADaVkmJxIRkZpQpXLz7LPPMmXKFFq1akWvXr2IiooCzu/F6d69e7UGFKlOI7qEcX1kMAXFdqYt3IXdrnvfiIg4mypfCp6amkpKSgrdunXDaj3fkX766Sf8/f2JjIys1pDVSZeCy9GzOdz497XkFhYTM6YLd/ZqYXYkERG5hBq/FBwgNDSU7t27c/z4cY4dOwZAr1696nSxEQFoHujDE4PbAxCzLJ60rDyTE4mISHWqUrmx2+28+OKLBAQE0LJlS1q0aEHDhg156aWXsNvt1Z1RpNqN69OKLs0CyMwr4sX/7jE7joiIVKMqlZvp06fz3nvv8corr7Bt2za2bt3KzJkzeffdd3nmmWeqO6NItXN3sxIzpgtuVgv/25nCqr0nzI4kIiLVpErn3DRt2pTZs2eXPA38gq+//pqHH3645DBVXaRzbuS3Zi6LZ87aQzRr6M2Kx/vja3M3O5KIiJSjxs+5OXPmTLnn1kRGRnLmjO7+KvXHpBva0TzQm2Ppufx95T6z44iISDWoUrnp1q0b7733Xpn57733Hl27dr3sUCK1xcfTnRmjOwMw94fDxB3NMDmRiIhcrirtg3/ttdcYMWIE3333HVFRUVgsFjZs2EBycjLLli2r7owiNeq6iGBu7taUJTuOM3XhTr6ecC3ublW+kFBERExWpX/BBwwYwL59+7jllltIT0/nzJkzjBkzht27dzN37tzqzihS4565qSMB3h7sPp7J3B8SzY4jIiKXoco38SvPjh07uOqqqygurrsPJdQJxXIx/9mczJMLduLt4caKx/sTHuRjdiQREflFrdzET8TZ/KFnc3q3CSK3sJinF++iGnu/iIjUIpUbkV9YLBZm3tIFT3cra/adZMmO42ZHEhGRKlC5EfmNNk0a8MjAtgC8+N89pOcUmJxIREQqq1JXS40ZM8bhz9PT0y8ni0id8NcBV7Bkx3H2p51j5rJ4Xrutm9mRRESkEiq15yYgIMDh1LJlS+67776ayipSKzzdzz+aAeA/W46y8eBpkxOJiEhlVOvVUvWBrpaSipq+KI5Pf0yiTWNflj3WDy8PN7MjiYi4LF0tJVINnhwaSbCfjUOnsvlg9QGz44iISAWp3IhcRIC3By/c3AmAWWsOsu9ElsmJRESkIlRuRBwY2jmUGzqEUFhsEL0wDrvdpY7iiojUSyo3Ig5YLBZeHNUJX083fj5yls9+SjI7koiIXILKjcglNG3ozZQhEQC8+s1eTmTmmZxIREQcUbkRqYD7olrRrXkAWflFvPDf3WbHERERB1RuRCrAzWohZkxX3KwWlsWlsnLPCbMjiYjIRajciFRQx6b+/KVfGwCe/XoX5/KLTE4kIiLlUbkRqYTHBrWjRZAPKRl5vP5tgtlxRESkHCo3IpXg7enGy7d0BuCfGxPZnpxubiARESlD5Uakkvq1a8KY7s0wDJi6YCeFxXazI4mIyG+o3IhUwfQRHQj08WBvahYfrT9sdhwREfkNlRuRKmjUwMb0ER0BeOu7fRw5nW1yIhERuUDlRqSKbr2qGX2uaEReoZ2nF+/CMPRoBhGRukDlRqSKLBYLM2/pgs3dyrr9p1i8/ZjZkUREBJUbkcvSqrEvjw5qB8BL/4vnTHaByYlERETlRuQyPdi/DREhfpzJLuDlpfFmxxERcXkqNyKXycPNSsytXbBYYMHWo/xw4JTZkUREXJrKjUg1uKpFIPf2bgnA9EVx5BUWm5xIRMR1mVpu1q5dy8iRI2natCkWi4XFixc7HB8bG4vFYikz7d27t3YCizjwf0MiCPX3IvF0Du+u2m92HBERl2VqucnOzqZbt2689957lVouISGBlJSUkqldu3Y1lFCk4vy8PHhhVCcAPlxziL2pmSYnEhFxTe5mfviwYcMYNmxYpZcLDg6mYcOG1R9I5DIN6RTKkE4hfLv7BFMXxLHgoT64WS1mxxIRcSn18pyb7t27ExYWxqBBg1i9erXDsfn5+WRmZpaaRGrSCzd3poHNne3J6Xz64xGz44iIuJx6VW7CwsKYM2cOCxYsYOHChURERDBo0CDWrl170WViYmIICAgomcLDw2sxsbii0AAvnhoaAcBryxNIycg1OZGIiGuxGHXknvEWi4VFixYxevToSi03cuRILBYLS5YsKffn+fn55Ofnl7zOzMwkPDycjIwM/P39LyeyyEXZ7Qa3zd7A1qR0BncMYc59Pc2OJCJSr2VmZhIQEFCh39/1as9NeXr37s3+/Re/MsVms+Hv719qEqlpVquFmDFdcbdaWLHnBMt3pZodSUTEZdT7crNt2zbCwsLMjiFSRkSoH38d0AaA55bsIiuv0OREIiKuwdSrpc6dO8eBAwdKXh8+fJjt27cTFBREixYtiI6O5tixY3zyyScAvPXWW7Rq1YpOnTpRUFDA/PnzWbBgAQsWLDDrK4g49Mj17Vi6M4XE0zn87dsEXhzV2exIIiJOz9Q9N1u2bKF79+50794dgMmTJ9O9e3eeffZZAFJSUkhKSioZX1BQwJQpU+jatSv9+vVj/fr1LF26lDFjxpiSX+RSvDzcmHlLFwD+tekIPx85a3IiERHnV2dOKK4tlTkhSaS6TPlyB1/9fJSIED/++0hfPN3r/RFhEZFa5VInFIvUB9OHdyDI15OEE1n8v3WHzI4jIuLUVG5EakGgryfP3NQBgLe/38/hU9kmJxIRcV4qNyK1ZPSVzejXrjEFRXamL4rDxY4Ii4jUGpUbkVpisVh4eXQXvDysbDh4mgVbj5kdSUTEKanciNSiFo18mHRDewBmLN3D6XP5l1hCREQqS+VGpJY90Lc1HcL8Sc8pZMbSeLPjiIg4HZUbkVrm4WbllTFdsFhg0bZjrN130uxIIiJOReVGxATdwhsyrk8rAKYvjiO3oNjcQCIiTkTlRsQkTwyOICzAi+Qzubz9/cUf/ioiIpWjciNikgY2d1765VlT/2/dIfYczzQ5kYiIc1C5ETHRDR1DGN4llGK7QfTCnRTbde8bEZHLpXIjYrLnR3bCz8udHUcz+GRjotlxRETqPZUbEZMF+3sxdVgkAH/7NoFj6bkmJxIRqd9UbkTqgDuvbkHPloHkFBTz7OJdejSDiMhlULkRqQOsVgsxY7rg4Wbh+71pfLMr1exIIiL1lsqNSB3RLsSPhwZcAcDzS3aTkVtociIRkfpJ5UakDnl4YFvaNPYlLSuf15bvNTuOiEi9pHIjUod4ebgxc0wXAD79MYnNiWdMTiQiUv+o3IjUMb3bNOL2nuEARC+MI79Ij2YQEakMlRuROih6eCSNG3hyIO0cH645ZHYcEZF6ReVGpA5q6OPJsyM7AfDeqgMcPHnO5EQiIvWHyo1IHTWyaxjXRTShoNjOtIVxFBXbzY4kIlIvqNyI1FEWi4WXRnXG28ONHw+fYdjb61i9N003+BMRuQSVG5E6LDzIh7//sRsNfTzYn3aOP83bzL0f/aQniIuIOGAxXOw/AzMzMwkICCAjIwN/f3+z44hUSEZOIe/HHmDeD4kUFNuxWOAPPZrzxOAIQvy9zI4nIlLjKvP7W+VGpB5JOp3Dq9/uZenOFAC8Pdz464A2PNi/DT6e7ianExGpOSo3DqjciDP4+chZZizdw7akdABC/G08MTiCW69qjpvVYm44EZEaoHLjgMqNOAvDMFgal8Kry/eSfCYXgA5h/kwf3oG+7RqbnE5EpHqp3DigciPOJr+omH9uSOTdVQfIyisC4PrIYKKHRdIuxM/kdCIi1UPlxgGVG3FWZ7ILeOf7/czfdIQiu4Gb1cIdV4fz+I3tadzAZnY8EZHLonLjgMqNOLtDJ8/xyjd7WbHnBAANbO48dN0VPNC3NV4ebianExGpGpUbB1RuxFVsOnSal5fGE3csA4BmDb35vyER3NytKVaddCwi9YzKjQMqN+JK7HaDr3cc42/LEziekQdA1+YBPD2iI71aB5mcTkSk4lRuHFC5EVeUV1jMR+sP88HqA2QXFAMwpFMIU4d1oHVjX5PTiYhcmsqNAyo34spOZuXz5nf7+PynJOwGuFst3NO7JY8Nakegr6fZ8URELkrlxgGVGxHYfyKLmcviWZ1wEgB/L3ceub4d9/Vpic1dJx2LSN2jcuOAyo3Ir9bvP8WMpXvYm5oFQIsgH54aGsnwLqFYLDrpWETqDpUbB1RuREorthss+Pkor69IIC0rH4CrWjRk+oiO9GgZaHI6EZHzVG4cULkRKV92fhFz1h5iztpD5BaeP+l4RNcwpg6NJDzIx+R0IuLqVG4cULkRcexEZh6vf5vAV1uPYhjg6WZl3LWtmDCwLQHeHmbHExEXpXLjgMqNSMXsPp7BzGXx/HDgNACBPh48Nqgdd/duiYeb1eR0IuJqVG4cULkRqTjDMIhNOMnLy+I5kHYOgDaNfZk6LJIbO4bopGMRqTUqNw6o3IhUXlGxnc83J/Pmyn2czi4A4JrWQTw9oiNdmgeYnE5EXIHKjQMqNyJVl5VXyKzYg3y0/jD5RXYAxnRvxpQhETRt6G1yOhFxZio3DqjciFy+Y+m5/G35XhZvPw6Azd3Kn/u15qHr2tLA5m5yOhFxRio3DqjciFSfHcnpvLw0np8SzwDQuIEnj9/Yntt7huOuk45FpBpV5ve3qf/6rF27lpEjR9K0aVMsFguLFy++5DJr1qyhR48eeHl50aZNG2bPnl3zQUWkXN3CG/LFX3vz4b09aN3Yl1PnCpi+aBfD31nH6oQ0XOy/nUSkjjC13GRnZ9OtWzfee++9Co0/fPgww4cPp1+/fmzbto1p06bx6KOPsmDBghpOKiIXY7FYGNIplG8n9ee5kR1p6OPBvhPn+NPczdz38U/Ep2SaHVFEXEydOSxlsVhYtGgRo0ePvuiYp556iiVLlhAfH18yb/z48ezYsYONGzdW6HN0WEqkZmXkFPLe6v38c8MRCortWCzwxx7hPDG4PcH+XmbHE5F6qt4clqqsjRs3Mnjw4FLzhgwZwpYtWygsLDQplYj8VoCPB9NHdOS7yQMY0SUMw4AvtiRz3euxvP3dfnIKisyOKCJOrl6Vm9TUVEJCQkrNCwkJoaioiFOnTpW7TH5+PpmZmaUmEal5LRr58P7dV7HgoSi6t2hITkExb363j4Gvx/KfLckU2+vETmMRcUL1qtwAZe6IeuGo2sXulBoTE0NAQEDJFB4eXuMZReRXPVoGsfChPrx3V3fCg7w5kZnPk1/t5KZ31/PDgfL/o0RE5HLUq3ITGhpKampqqXlpaWm4u7vTqFGjcpeJjo4mIyOjZEpOTq6NqCLyGxaLhZu6NuW7yQOYNjwSPy934lMyufsfP3L/vM0cSMsyO6KIOJF6VW6ioqJYuXJlqXkrVqygZ8+eeHiU/7Rim82Gv79/qUlEzGFzd+PB/lew5v8GMq5PK9ytFlbtTWPIW+t4enEcp87lmx1RRJyAqeXm3LlzbN++ne3btwPnL/Xevn07SUlJwPm9Lvfdd1/J+PHjx3PkyBEmT55MfHw8H3/8MR999BFTpkwxI76IVFGQryfP39yJFY/358aOIRTbDeZvSuK6v8XyQewB8gqLzY4oIvWYqZeCx8bGMnDgwDLzx44dy7x58xg3bhyJiYnExsaW/GzNmjU8/vjj7N69m6ZNm/LUU08xfvz4Cn+mLgUXqXs2HTrNjKV72HXs/An/zRp6839DIri5W1OsVj15XET0+AWHVG5E6ia73eDrHcd4bXkCKRl5AHRrHsD0ER3p1TrI5HQiYjaVGwdUbkTqtrzCYj5af5gPVh8gu+D84akhnUKYOqwDrRv7mpxORMyicuOAyo1I/XAyK583v9vH5z8lYTfA3Wrh3qiWPHp9OwJ9Pc2OJyK1TOXGAZUbkfpl34ksZi6LJzbhJAD+Xu48Oqgd90a1xObuZnI6EaktKjcOqNyI1E/r9p/k5aXx7E09f0+cFkE+PDU0kuFdQi96E08RcR4qNw6o3IjUX8V2g69+Tub1Ffs4mXX+njg9WgYyfUQHrmoRaHI6EalJKjcOqNyI1H/Z+UXMWXuIOWsPkfvLPXFu6hrGU0MjCQ/yMTmdiNQElRsHVG5EnEdqRh5vrEjgq61HMQzwdLPyp2tb8fDAtgR4l3/XchGpn1RuHFC5EXE+u49nMHNZPD8cOA1AoI8Hk25oz13XtMDDrV49ZUZELkLlxgGVGxHnZBgGqxPSmLlsLwfSzgHQpokv0cM6cEOHYJ10LFLPqdw4oHIj4tyKiu38e3Myb63cx+nsAgB6twli+vCOdGkeYHI6EakqlRsHVG5EXENWXiGzYg/yj/WHKSiyAzCmezOmDImgaUNvk9OJSGWp3DigciPiWo6l5/K35XtZvP04ADZ3K3/p14bx111BA5u7yelEpKJUbhxQuRFxTTuS03l5aTw/JZ4BoHEDG5NvbM8fezbHXScdi9R5KjcOqNyIuC7DMPh29wle+SaexNM5ALQPacC04R24LiLY5HQi4ojKjQMqNyJSUGRn/qYjvLNqP+k5hQD0a9eYacM70CFM/y6I1EUqNw6o3IjIBRk5hby3ej/zNiRSWGxgtcAfeoTzxOD2BPt7mR1PRH5D5cYBlRsR+b2k0zm8unwvS+NSAPDxdOOv/a/gL/1b4+Opk45F6gKVGwdUbkTkYn4+coYZS+PZlpQOQIi/jSmDI7j1quZYrboJoIiZVG4cULkREUcMw+B/O1N4dflejp7NBaBjmD9Pj+hAn7aNTU4n4rpUbhxQuRGRisgrLOafGxJ5b/UBsvKKABgUGUz08EjaBvuZnE7E9ajcOKByIyKVcSa7gLe/28enPyZRZDdws1q4s1c4k25oT+MGNrPjibgMlRsHVG5EpCoOnjzHK9/sZeWeEwA0sLnz8MAruP/a1nh5uJmcTsT5qdw4oHIjIpdj48HTvLxsD7uOZQLQrKE3Tw6NYGTXpjrpWKQGqdw4oHIjIpfLbjdYvP0Yf/s2gZSMPAC6NQ/g6Zs6cnWrIJPTiTgnlRsHVG5EpLrkFhTz0fpDzIo9SHZBMQBDO4UydVgkrRr7mpxOxLmo3DigciMi1S0tK483V+7ni81J2A3wcLNwb+9WPDqoLQ19PM2OJ+IUVG4cULkRkZqy70QWM5fFE5twEgB/L3ceHdSOe6NaYnPXSccil0PlxgGVGxGpaev2n+TlpfHsTc0CoEWQD1OHRTKscygWi046FqkKlRsHVG5EpDYU2w2++jmZ11fs42RWPgA9WwYyfUQHurcINDmdSP2jcuOAyo2I1Kbs/CI+XHuIOWsPkldoB2Bkt6Y8OSSC8CAfk9OJ1B8qNw6o3IiIGVIz8nh9RQILth7FMMDTzcqfrm3FwwPbEuDtYXY8kTpP5cYBlRsRMdPu4xm8vDSeDQdPAxDo48GkG9pz1zUt8HCzmpxOpO5SuXFA5UZEzGYYBqsT0nh5aTwHT2YD0KaJL9HDOnBDh2CddCxSDpUbB1RuRKSuKCy28/nmZN5auY/T2QUA9G4TxNMjOtK5WYDJ6UTqFpUbB1RuRKSuycwrZFbsQT5af5iCIjsWC9zSvRn/NySCsABvs+OJ1AkqNw6o3IhIXXX0bA5/+zaBr7cfB8DLw8pf+rXhrwOuoIHN3eR0IuZSuXFA5UZE6rrtyem8vHQPmxPPAtC4gY3JN7bnjz2b466TjsVFqdw4oHIjIvWBYRh8u/sEr3wTT+LpHAAiQvyIHh7JdRHBJqcTqX0qNw6o3IhIfVJQZGf+piO8/f1+MnILAejXrjHTR3QgMlT/honrULlxQOVGROqjjJxC3l21n39uTKSw2MBqgT/2DGfy4PYE+3mZHU+kxqncOKByIyL12ZHT2by6fC/L4lIB8PF0Y/yAK/hLvzZ4e+rJ4+K8VG4cULkREWewJfEMM5bGsz05HYAQfxv/NySSMd2bYbXqJoDifFRuHFC5ERFnYRgG/9uZwqvL93L0bC4AHcP8eXpEB/q0bWxyOpHqpXLjgMqNiDibvMJi/rkhkfdWHSArvwiAQZHBRA/vQNvgBianE6keKjcOqNyIiLM6k13A29/tY/6PSRTbDdysFu7q1YJJN7SjUQOb2fFELovKjQMqNyLi7A6ePEfMsr18F38CAD+bOw8PbMufrm2Fl4dOOpb6SeXGAZUbEXEVGw+e5uVle9h1LBOAZg29eXJoBDd3a6onj0u9U5nf36bfx/uDDz6gdevWeHl50aNHD9atW3fRsbGxsVgsljLT3r17azGxiEj9EHVFI5ZM6Msbf+hGqL8Xx9Jzeezz7Yz+YAObE8+YHU+kxpj6JLYvvviCSZMm8cEHH3Dttdfy4YcfMmzYMPbs2UOLFi0uulxCQkKp1takSZPaiCsiUu9YrRZu7dGc4V3C+Gj9IT6IPciO5HT+MHsjQzqF0K9dE5r42Qj2s9Hkl8nmrkNXUr+Zeljqmmuu4aqrrmLWrFkl8zp06MDo0aOJiYkpMz42NpaBAwdy9uxZGjZsWKXP1GEpEXFlaVl5vLlyP19sTsJ+kX/9A7w9SsrOb0tPsJ9XqXkB3h46vCW1pjK/v03bc1NQUMDPP//M1KlTS80fPHgwGzZscLhs9+7dycvLo2PHjjz99NMMHDjwomPz8/PJz88veZ2ZmXl5wUVE6rFgPy9ixnRhXJ9WfPbjEY5n5JGWlc+prHxOZuVTUGwnI7eQjNxC9qedc/henm7WkuLz29Lz+xLUuIENT3fTz4IQF2JauTl16hTFxcWEhISUmh8SEkJqamq5y4SFhTFnzhx69OhBfn4+//rXvxg0aBCxsbH079+/3GViYmJ44YUXqj2/iEh9FhHqxwujOpeaZxgGGbmFpP1SdNKy8s7/mZnPyXO//TOPzLwiCortHEvP5Vh67iU/L9DHo0zpaVLOXiF/L3ftDZLLZuo5N0CZjdgwjItu2BEREURERJS8joqKIjk5mddff/2i5SY6OprJkyeXvM7MzCQ8PLwakouIOBeLxUJDH08a+njSPsTP4di8wmJOncv/TRE6/+fJC4Wo5HU+RXaDszmFnM0pJOFElsP3tblbHe4FuvC6cQNP3N20N0jKZ1q5ady4MW5ubmX20qSlpZXZm+NI7969mT9//kV/brPZsNl08yoRkerk5eFG80Afmgf6OBxntxuk5xZedC/Qyay8kiKUlVdEfpGdo2dzSx4ncTEWCwT5eF70fKDf/u8GNu0NcjWmlRtPT0969OjBypUrueWWW0rmr1y5klGjRlX4fbZt20ZYWFhNRBQRkctktVoI8vUkyNeTyFDHY3MLLuwNKr33p6QQ/TL/1LkCiu0Gp7MLOJ1dwN5Ux3uDvD3cfrf3p3QhujCvUQMbbnroqFMw9bDU5MmTuffee+nZsydRUVHMmTOHpKQkxo8fD5w/pHTs2DE++eQTAN566y1atWpFp06dKCgoYP78+SxYsIAFCxaY+TVERKQaeHu6ER7kQ3iQ471BxXaDszkFpc4BKr036NfpXH4RuYXFJJ3JIelMjsP3tVogyLe8EmSjye/2DPnaTD+rQxww9W/n9ttv5/Tp07z44oukpKTQuXNnli1bRsuWLQFISUkhKSmpZHxBQQFTpkzh2LFjeHt706lTJ5YuXcrw4cPN+goiIlLL3KwWGjc4fxXWpWTnF5U+N+h3RejCn6fP5WM34NS5fE6dy4cUx+/r6+lWZu9PeXuFgnw9tTfIBHr8goiIuLzzh7l+s/fnN3uBfnuYLC0zn9zC4gq/r5vVQiNfT4L9bTRp8Jtzg355/dsi5O2pmyc6Ui/ucyMiIlJXuFktBPt5Eezndcmx5/KLHO4FSsvM49S5fE5nnz83KO2XYnQpfjb3ci+PL9kb9EshCvTxxKq9QQ6p3IiIiFRCA5s7DWzutG7s63BcYbGdM9kXzg3KO/9n1u+KUNb5+flFdrLyi8jKL+LQqWyH7+v+y2G5kr1BF/YC+XuVfu1nc9mnwKvciIiI1AAPNysh/l6E+HsBARcdZxgGWSV7g0qfJH3yd3uFzmQXUGQ3SM3MIzUz75IZ/L3cHewF8iopQg19nOtRGio3IiIiJrJYLPh7eeDv5cEVTRo4HFtQZP/13KBSe4HyyhweKyiyk5lXRGZeEQdPOt4b5OFmKXfvz69//nrzxPrwYFWVGxERkXrC091KWIA3YQHeDscZhkFmblG5pef35wql5xRSWGxwPCOP4xmX3hvU0MejbPEpU4i8CPDxqK6vXWkqNyIiIk7GYrEQ4ONBgI8HbYMdP0ojv6iYU+cKzpee358TVHL12PlCVFhskJ5TSHqO4wer+tnciXthSHV/rQpTuREREXFhNnc3mjX0plnDS+8NSs8pLHso7Ld3k/7lsvmK3IOoJqnciIiIyCVZLBYCfT0J9L30g1ULi+21lKp8eqSqiIiIVCsPk5/YrnIjIiIiTkXlRkRERJyKyo2IiIg4FZUbERERcSoqNyIiIuJUVG5ERETEqajciIiIiFNRuRERERGnonIjIiIiTkXlRkRERJyKyo2IiIg4FZUbERERcSoqNyIiIuJU3M0OUNsMwwAgMzPT5CQiIiJSURd+b1/4Pe6Iy5WbrKwsAMLDw01OIiIiIpWVlZVFQECAwzEWoyIVyInY7XaOHz+On58fFoulWt87MzOT8PBwkpOT8ff3r9b3djZaVxWndVVxWleVo/VVcVpXFVdT68owDLKysmjatClWq+Ozalxuz43VaqV58+Y1+hn+/v7a+CtI66ritK4qTuuqcrS+Kk7rquJqYl1dao/NBTqhWERERJyKyo2IiIg4FZWbamSz2Xjuueew2WxmR6nztK4qTuuq4rSuKkfrq+K0riquLqwrlzuhWERERJyb9tyIiIiIU1G5EREREaeiciMiIiJOReVGREREnIrKTSV98MEHtG7dGi8vL3r06MG6descjl+zZg09evTAy8uLNm3aMHv27FpKar7KrKvY2FgsFkuZae/evbWY2Bxr165l5MiRNG3aFIvFwuLFiy+5jKtuV5VdV666XcXExHD11Vfj5+dHcHAwo0ePJiEh4ZLLuep2VZX15arb1qxZs+jatWvJDfqioqL45ptvHC5jxnalclMJX3zxBZMmTWL69Ols27aNfv36MWzYMJKSksodf/jwYYYPH06/fv3Ytm0b06ZN49FHH2XBggW1nLz2VXZdXZCQkEBKSkrJ1K5du1pKbJ7s7Gy6devGe++9V6HxrrxdVXZdXeBq29WaNWuYMGECmzZtYuXKlRQVFTF48GCys7Mvuowrb1dVWV8XuNq21bx5c1555RW2bNnCli1buP766xk1ahS7d+8ud7xp25UhFdarVy9j/PjxpeZFRkYaU6dOLXf8k08+aURGRpaa99e//tXo3bt3jWWsKyq7rlavXm0AxtmzZ2shXd0FGIsWLXI4xpW3q9+qyLrSdnVeWlqaARhr1qy56BhtV7+qyPrStvWrwMBA4x//+Ee5PzNru9KemwoqKCjg559/ZvDgwaXmDx48mA0bNpS7zMaNG8uMHzJkCFu2bKGwsLDGspqtKuvqgu7duxMWFsagQYNYvXp1Tcast1x1u7ocrr5dZWRkABAUFHTRMdquflWR9XWBK29bxcXFfP7552RnZxMVFVXuGLO2K5WbCjp16hTFxcWEhISUmh8SEkJqamq5y6SmppY7vqioiFOnTtVYVrNVZV2FhYUxZ84cFixYwMKFC4mIiGDQoEGsXbu2NiLXK666XVWFtqvzT1KePHkyffv2pXPnzhcdp+3qvIquL1fetuLi4mjQoAE2m43x48ezaNEiOnbsWO5Ys7Yrl3sq+OWyWCylXhuGUWbepcaXN98ZVWZdRUREEBERUfI6KiqK5ORkXn/9dfr371+jOesjV96uKkPbFUycOJGdO3eyfv36S47VdlXx9eXK21ZERATbt28nPT2dBQsWMHbsWNasWXPRgmPGdqU9NxXUuHFj3Nzcyux5SEtLK9NKLwgNDS13vLu7O40aNaqxrGaryroqT+/evdm/f391x6v3XHW7qi6utF098sgjLFmyhNWrV9O8eXOHY7VdVW59lcdVti1PT0/atm1Lz549iYmJoVu3brz99tvljjVru1K5qSBPT0969OjBypUrS81fuXIlffr0KXeZqKioMuNXrFhBz5498fDwqLGsZqvKuirPtm3bCAsLq+549Z6rblfVxRW2K8MwmDhxIgsXLmTVqlW0bt36ksu48nZVlfVVHlfYtspjGAb5+fnl/sy07apGT1d2Mp9//rnh4eFhfPTRR8aePXuMSZMmGb6+vkZiYqJhGIYxdepU49577y0Zf+jQIcPHx8d4/PHHjT179hgfffSR4eHhYXz11VdmfYVaU9l19eabbxqLFi0y9u3bZ+zatcuYOnWqARgLFiww6yvUmqysLGPbtm3Gtm3bDMD4+9//bmzbts04cuSIYRjarn6rsuvKVberhx56yAgICDBiY2ONlJSUkiknJ6dkjLarX1VlfbnqthUdHW2sXbvWOHz4sLFz505j2rRphtVqNVasWGEYRt3ZrlRuKun99983WrZsaXh6ehpXXXVVqUsFx44dawwYMKDU+NjYWKN79+6Gp6en0apVK2PWrFm1nNg8lVlXr776qnHFFVcYXl5eRmBgoNG3b19j6dKlJqSufRcuKf39NHbsWMMwtF39VmXXlatuV+WtI8CYO3duyRhtV7+qyvpy1W3r/vvvL/l3vUmTJsagQYNKio1h1J3tymIYv5zZIyIiIuIEdM6NiIiIOBWVGxEREXEqKjciIiLiVFRuRERExKmo3IiIiIhTUbkRERERp6JyIyIiIk5F5UZEhPMP8Vu8eLHZMUSkGqjciIjpxo0bh8ViKTMNHTrU7GgiUg+5mx1ARARg6NChzJ07t9Q8m81mUhoRqc+050ZE6gSbzUZoaGipKTAwEDh/yGjWrFkMGzYMb29vWrduzZdffllq+bi4OK6//nq8vb1p1KgRDz74IOfOnSs15uOPP6ZTp07YbDbCwsKYOHFiqZ+fOnWKW265BR8fH9q1a8eSJUtq9kuLSI1QuRGReuGZZ57h1ltvZceOHdxzzz3ceeedxMfHA5CTk8PQoUMJDAxk8+bNfPnll3z33XelysusWbOYMGECDz74IHFxcSxZsoS2bduW+owXXniBP/7xj+zcuZPhw4dz9913c+bMmVr9niJSDWr80ZwiIpcwduxYw83NzfD19S01vfjii4ZhnH9q8/jx40stc8011xgPPfSQYRiGMWfOHCMwMNA4d+5cyc+XLl1qWK1WIzU11TAMw2jatKkxffr0i2YAjKeffrrk9blz5wyLxWJ888031fY9RaR26JwbEakTBg4cyKxZs0rNCwoKKvnfUVFRpX4WFRXF9u3bAYiPj6dbt274+vqW/Pzaa6/FbreTkJCAxWLh+PHjDBo0yGGGrl27lvxvX19f/Pz8SEtLq+pXEhGTqNyISJ3g6+tb5jDRpVgsFgAMwyj53+WN8fb2rtD7eXh4lFnWbrdXKpOImE/n3IhIvbBp06YyryMjIwHo2LEj27dvJzs7u+TnP/zwA1arlfbt2+Pn50erVq34/vvvazWziJhDe25EpE7Iz88nNTW11Dx3d3caN24MwJdffknPnj3p27cvn376KT/99BMfffQRAHfffTfPPfccY8eO5fnnn+fkyZM88sgj3HvvvYSEhADw/PPPM378eIKDgxk2bBhZWVn88MMPPPLII7X7RUWkxqnciEidsHz5csLCwkrNi4iIYO/evcD5K5k+//xzHn74YUJDQ/n000/p2LEjAD4+Pnz77bc89thjXH311fj4+HDrrbfy97//veS9xo4dS15eHm+++SZTpkyhcePG3HbbbbX3BUWk1lgMwzDMDiEi4ojFYmHRokWMHj3a7CgiUg/onBsRERFxKio3IiIi4lR0zo2I1Hk6ei4ilaE9NyIiIuJUVG5ERETEqajciIiIiFNRuRERERGnonIjIiIiTkXlRkRERJyKyo2IiIg4FZUbERERcSoqNyIiIuJU/j9pE5Ut4UUgFQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(losses)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss Over Epochs')\n",
    "plt.show()\n",
    "\n",
    "# 보충: validation loss를 같이 그려서 비교하는 사례 https://www.geeksforgeeks.org/training-and-validation-loss-in-deep-learning/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 보충 코드\n",
    "\n",
    "- [validation loss를 같이 그려서 비교하는 사례](https://www.geeksforgeeks.org/training-and-validation-loss-in-deep-learning/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 결과 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(128, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 파일로 저장했던 네트워크의 가중치들 읽어들이기\n",
    "model.load_state_dict(torch.load('model_004.pth', map_location=device, weights_only=True))\n",
    "model.eval() # dropout을 사용하지 않음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.63\t  me\n",
      "9.61\t  \n",
      "8.71\t  I\n",
      "8.46\t  about\n",
      "8.03\t  if\n",
      "7.56\t  not\n",
      "7.35\t  an\n",
      "7.18\t  a\n",
      "6.72\t  people\n",
      "6.50\t  it\n",
      " me\n"
     ]
    }
   ],
   "source": [
    "idx = tokenizer.encode('Dobby is') # 토큰 id의 list\n",
    "idx = torch.tensor(idx).unsqueeze(0).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    logits = model(idx)\n",
    "\n",
    "logits = logits[:, -1, :]\n",
    "\n",
    "# 가장 확률이 높은 단어 10개 출력\n",
    "top_logits, top_indices = torch.topk(logits, 10)\n",
    "for p, i in zip(top_logits.squeeze(0).tolist(), top_indices.squeeze(0).tolist()):\n",
    "    print(f'{p:.2f}\\t {tokenizer.decode([i])}')\n",
    "    \n",
    "# 가장 확률이 높은 단어 출력\n",
    "idx_next = torch.argmax(logits, dim=-1, keepdim=True)\n",
    "flat = idx_next.squeeze(0) # 배치 차원 제거 torch.Size([1])\n",
    "out = tokenizer.decode(flat.tolist()) # 텐서를 리스트로 바꿔서 디코드\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
